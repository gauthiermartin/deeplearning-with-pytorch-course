{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjpdj7BqxcCoMAVASwoa9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauthiermartin/pytorch-deep-learning-course/blob/main/04_pytorch_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets\n",
        "\n",
        "We've used some datasets with PyTorch before.\n",
        "\n",
        "But how to get your own data into PyTorch\n",
        "\n",
        "One of the ways to do so is via : custom datasets.\n",
        "\n",
        "## Domain libraries\n",
        "\n",
        "Depending on what you're worjing on (vision, text, audio, ...) look for existing dataloader in each of those domain libraries to base your implementation on it\n",
        "\n",
        "**Resources:**\n",
        "* Book version of the course material for chapter 6 - https://www.learnpytorch.io/04_pytorch_custom_datasets/\n",
        "\n",
        "* Ground truth version of the notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/04_pytorch_custom_datasets.ipynb\n"
      ],
      "metadata": {
        "id": "LXq38bLj5yO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = \"gpu\"if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "zButFZrm58o5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3wBa5ndG8XnR",
        "outputId": "65f8828f-8a18-43d6-b562-1a686ccae1f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJEP_vEx9A1F",
        "outputId": "01eefcf3-8301-41c9-adc4-5dbe913462b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 21 12:00:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get Data\n",
        "\n",
        "Our dataset is a subset of the food101 dataset, which starts with 101 classes ours will starte with only 3 classes of food and 10% of images per classes (~ 75 training, 25 testing)\n",
        "\n",
        "Why are we doing this ?  \n",
        "\n",
        "When starting out ML Projects, it's important to try thing from a small subset of data to speed up experiments"
      ],
      "metadata": {
        "id": "Y6p9vBVl-DVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exist, skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Download\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak and sushi data\")\n",
        "    f.write(request.content)\n",
        "\n",
        "  # Unzip\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak sushi data\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwgeU7G4-F9u",
        "outputId": "6f07d025-492d-46c6-f95c-0210a3f78e22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi does not exist, creating one...\n",
            "Downloading pizza, steak and sushi data\n",
            "Unzipping pizza, steak sushi data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2. Becoming one with the data (data preparation and data exploration)\n",
        ""
      ],
      "metadata": {
        "id": "X0im9DHx_ZK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir path returning it's contents.\"\"\"\n",
        "\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "id": "3CUIeg1KCCLV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zDPqcwACnd6",
        "outputId": "78cb871d-9979-4f08-f34f-29aa3198e05b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in 'data/pizza_steak_sushi'\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'\n",
            "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'\n",
            "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'\n",
            "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'\n",
            "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'\n",
            "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'\n",
            "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'\n",
            "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and testing paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path  / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NagQIKqMC5sn",
        "outputId": "30e2b38f-9a9f-4a1f-f52d-00277fdaee08"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}